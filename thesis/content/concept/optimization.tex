\section{Optimization}
Our compiler does not only translate the source language Luie to the target language OpenQASM but can also apply optimizations to the program. Since quantum programs must be deterministic and, therefore, most language constructs are translated at compile time, many classical optimizations are inherently applied. The following, inherent optimizations are discuss in more detain in Sec.~\ref{sec:background_codeOptimization}.

The first kind of inherent optimizations are constant propagation and constant folding. 
While the target language does allow for expressions, they need to be constant. Furthermore, some language features that depend on expressions have no equivalent in the target language so that they, and their corresponding expressions, need to be evaluated at compile time; this is the case for, \eg, the control statements. Therefore, any variable is always constant and its value is propagated to be used in the evaluation of expressions. Further, each expression is evaluated at compile time such that constant propagation and constant folding are inherently applied.

Secondly, loop unrolling is always applied to all loop statements. OpenQASM does not allow for loop statements or any other method for the iteration of commands, besides the restrictive implicit iteration. Furthermore, quantum computer in general cannot provide the ability to iterate over gates since they operate on static circuits. Therefore, to allow for loop statements in our language, the loop is unrolled entirely at compile time. Additionally, for each iteration the current values of the loop iterator is propagated as a constant through the loop body.   

The last inherent optimization is function inlining. Our language provides the ability to define custom gates that consist of an arbitrary combination of gate applications and, possibly, control flow statements. While OpenQASM has a similar functionality, the composite gate OpenQASM provides are more restrictive; for example, they do not allow for registers as arguments to the gate. Furthermore, in contrast to classical computers, quantum computers do not natively support function calls or similar. Therefore, each time a composite gate is used, the compiler inline the gate body at the call site of the gate.   

\subsection{Optimization Rules}
After the code is translated, the compiler can perform additional peephole optimizations; these are not inherent to the translation of the program and, therefore, are optional. 
The peephole optimizations can be applied to the internal representation of the source language and most hardware-independent optimizations are usually applied to the intermediate representation instead of the target language. However, the peephole optimization rules only operate on sequences of gate applications such that control flow statements or composite gates may only hinder, not aid, the effectiveness of the optimization. The overall performance of the optimization may be increased by optimizing composite gates before inlining their code so that a gate that is called ten times only needs to be optimized once; nevertheless, inlining the gates before applying the rules may enable more optimizations and, thereby, increase the effectiveness at the cost of performance. Therefore, we apply the optimization rules after the code is translated.
\todo{Why do we need to apply to translated code and not intermediate? most optimizations typically on intermediate} 
Additionally, the user can not only specify whether optimizations are applied but also which to apply when using the compiler. In the following section, we discuss the different optimization rules that can be applied. Additionally, the theoretical background for the rules is discuss in Sec.~\ref{sec:background_circuitOptimization}.

The first kind of optimization rules are the null gate optimizations; they describe sequences of gate applications such that the resulting behavior is equivalent to applying the identity gate. In the case of classical computers, an example is the sequential execution of two negation operations. In contrast, a quantum example is the application of two successive Hadamard gates. While these optimizations can easily be performed by the programmer themselves for a simple list of instructions, the manual optimizations increases in complexity when using composite gates and control flow statements. Moreover, the programmer cannot remove two null gates that are contained in two different successive composite gates by hand. Therefore, the optimization rules can not only help to reduce the workload of the programmer but apply optimization rules are cannot be implemented without major changed to the program.

Next, the ``peeping control'' optimization rule also belongs to the null gate rules. However, its implementation requires some additional evaluations and, therefore, we separate it from the other null gate rules. The peeping control rule can remove a controlled gate from the circuit if value of the control wire is $\ket{0}$ at the position of the gate. To estimate the value of the control wire, the implementation needs to iterate over all previous gates on the wire. Therefore, while it is still a null gate, its implementation differs greatly from the other null gates. Furthermore, we implement an additional optimization that removes the control from the gate if the value of the control wire is known to be $\ket{1}$. While the rule does not reduce the gate count of the circuit, it can enable further optimization of the control wire. For example, two $X$ gate on the control wire can be separated by a controlled-not gate. If the value of the control is $\ket{1}$ when the controlled-not gate is applied, the control can be removed and the now successive $X$ gates can be removed with a null gate optimization. Since this optimization does not remove the gate from the circuit, it is not a null gate optimization.

Another optimization rule that the compiler implements it the ``Hadamard reduction'' rule. It implements the matrix equivalences for both the $X$ and $Z$ gate being surrounded by Hadamard gates, $HXH = Z$ and $HZH = X$. Thereby, the rule reduces the gate count of the circuit if the optimization rule is applied. However, the optimization rule does not remove the gate combination but replaces it with another; therefore, the rules is not a null gate optimization. 
\change{Dont like the description, cannot come up with better right now}
Similar to the null gate optimizations, the rules itself is not hard to apply by hand. However, in combination with the more complex statements available in the language, the application of the rule is not trivial and the compiler can optimize parts of the circuit that would have required major changes to optimize them manually.

Lastly, the control reversal optimization rule optimized a controlled-not gate that is surrounded by Hadamard gates on all wires. When applied, the four Hadamard gates are removed and the control and target qubits of the controlled-not gate are switched. Therefore, the gate count is reduced by four gates. As described in Sec.~\ref{sec:background_circuitOptimization}, the optimization is based on two Hadamard reductions and the control reversal of the controlled $Z$ gate. However, the reversal of the controlled $Z$ gate does not have any direct gain when applied; it can only enabled other optimizations. Furthermore, the application of the controlled $Z$ reversal may also disabled other optimizations. Therefore, an optimization algorithm using the rule would need to either test both possibilities or estimate the value of the application and, in turn, increasing the complexity of the optimization algorithm significantly. Because of this, our optimizations do not include the controlled $Z$ reversal but implement only the special use case of the rule, the control reversal optimization rule.

\subsection{Circuit Graph}
\label{sec:concept_circuitGraph}
% Quick link to paper: https://quantum-journal.org/papers/q-2023-11-08-1176/pdf/
While it is possible to directly apply optimizations to the program code or internal representation of that code, this approach can be tedious and error prone. For example, the easiest approach would be to iterate over the code and search for code sequences with more efficient but equivalent alternatives, similar to the peephole optimization pattern on classical computers presented in Sec.~\ref{sec:background_codeOptimization}. However, two consecutive gates operating on a single wire may be separated by multiple gate applications on different wires in the programmatic description. 
% An example of this is depicted in Fig.~\ref{fig:circuit_graph_unoptimized_code}. Here, a register with 3 qubits is initiated an  gate are applied to it. While the first two gates applied to the third qubit are are two Hadamard gates, they are separated by two gate applications in the code itself.
Therefore, many simple optimization rules may not be applied when using a simplistic algorithm. A more complex approach would be too subdivide the program into lists of gate application where the wires being operated on by each list are disjunct. While this approach can result in the application of more optimization rules, it will also miss possible applications and already requires a complex implementation. Furthermore, improving on this method only increases its complexity and, in turn, makes it more prone to errors. Therefore, the language does not directly apply the optimizations to the program but uses a circuit graph description, based on the graph described by Kreppel et al.~\cite{KMO*23}, to apply the optimizations.

The circuit graph is a graphical description of a quantum graph; it is a acyclic and directed graph. For each qubit in the circuit, there exist both an input node and an output node. Furthermore, each input node as exactly one outgoing vertex while each output node as exactly one incoming vertex. Besides the input and output nodes, all other nodes represent gates in the circuit. All gate nodes the number of incoming vertices is equivalent to the number of outgoing vertices. Additionally, the number of incoming, or outgoing, vertices is the same as the number of parameters of the gate. Importantly, in this case, any qubits controlling the application of the gate, \eg the first qubit in a controlled-not gate, do also count to the number of parameters. In turn, their exists a vertices pair of an incoming and outgoing vertex each that represent a qubit to which the gate is applied. Therefore, for each qubit, there exists one path from its input node to its output node such that all gates that are applied to it are visited in order of application.

\subsubsection{Graph Construction}
When using the circuit graph to optimize the quantum program, the first step is to systematically construct the graph from the program. The creation of the graph starts with the input and output nodes for each qubit in the circuit. For each declaration of a qubit in the program, a input and output node pair is created. If a register is declared, a pair is created separately for each qubit in the register, \ie for a register with size $n$, $n$ pairs are created in total. Next, the gate applications in the program can be iterated. For each gate application, a corresponding gate node is created. To insert this node into the graph, each qubit parameter requires an incoming vertex to this node and a corresponding outgoing vertex from the node. Additionally, the incoming node must come from the gate that was previously applied to the qubit or the input node if no gate was applied yet. Similarly, the outgoing gate must lead to the either the next applied gate or the corresponding output. Therefore, for each qubit, the vertex coming into the output node can be diverted to the gate node and an outgoing vertex from the gate to the output node can be created. Repeating this step for all gate applications in the program result in the circuit graph.

An example of a simple, unoptimized circuit graph is depicted in Fig.~\ref{fig:circuit_graph_unoptimized}. For simplicity, all applied gates are depicted in their corresponding node of the circuit graph. The circuit consist of three qubits, $q_0$, $q_1$, and $q_2$; their input and output nodes are depicted on the left and right of the graph respectively and are labeled with the corresponding qubit. Firstly, an $X$ is applied to the first qubit $q_0$. Than, a controlled-not gate is applied to the first two qubits $q_0$ and $q_1$, where $q_0$ is the controlling qubit. Simultaneously, two Hadamard gates $H$ are applied to the third qubit $q_2$. Lastly, another $X$ gate is applied to the first qubit $q_0$ while another controlled-not gate is applied to the second and third qubits $q_1$ and $q_2$. In this case, the second qubit $q_1$ is the controlling qubit.

\begin{figure}[htp]
    \centering     
    \includegraphics[width=.9\textwidth]{../figures/circuit_graph_unoptimized.pdf}
    \caption{An example of a simple, unoptimized circuit graph.}
    \label{fig:circuit_graph_unoptimized}
\end{figure}

\subsubsection{Graph Optimization}
The next step in the optimization process is the application of optimization rules, in this case peephole optimizations, to the circuit graph. To accomplish this, subgraphs of the graph need to be iterated systematically. Then, each subgraph is checked for an equivalent but more efficient or cost-effective alternative. If an alternative is found, the subgraph is replaced with it. In our case, we iterate over all possible subpaths of all qubit paths up to a certain length; this length depends on the maximum number of nodes that are affected by an optimization rule. A qubit path is a path that starts at the input node of a qubit and ends in the corresponding output node. Furthermore, it visits only the nodes corresponding to the gates that are applied to the qubit in the correct order. However, optimizing parts of the circuit may enable further optimizations. For example, after removing a gate combination, two previously separated Hadamard gates may now represent a null gate combination which can, in turn, also be removed. Therefore, the process needs to be repeated until no more optimizations were applied.

An example for this is the optimization process of the circuit graph depicted in Fig.~\ref{fig:circuit_graph_unoptimized}. Firstly, subpaths for the qubit path of the first qubit $q_0$ are iterated. Here, the subpath of node it the path with the first two gate nodes $X$ and $CX$. Since the $X$ node the child of the input node, we know that the value of the qubit will be $\ket{1}$ after the application. Therefore, we know that the controlled-not gate will always apply the $X$ gate to the second qubit $q_1$ and we can replace the $CX$ gate node with a simple $X$ node that is only visited by the second qubit's path. For simplicity, we assume that the optimizations are only applied after all subpaths are iterated such that there are no optimization that can be applied to the second qubit in this round of the optimizations. However, in out later implementation, the optimizations are applied while iterating over the circuit. Lastly, on the third qubit wire, there are two consecutive Hadamard gates that can be removed. Overall, the first round of optimizations results in the circuit graph depicted in Fig.~\ref{fig:circuit_graph_first_optimized}. 
 
\begin{figure}[htp]
    \centering     
    \begin{minipage}{.6\textwidth}
        \centering     
        \includegraphics[width=\textwidth]{../figures/circuit_graph_optimized_firststep.pdf}
        \caption{Circuit graph after the first optimization.}
        \label{fig:circuit_graph_first_optimized}
    \end{minipage}
    \hfill
    \begin{minipage}{.35\textwidth}
        \centering     
        \includegraphics[width=\textwidth]{../figures/circuit_graph_optimized_complete.pdf}
        \caption{Completely optimized graph.}
        \label{fig:circuit_graph_optimized_complete}
    \end{minipage}
\end{figure}

In the next optimization round, the two $X$ gates on the first qubit wire are now applied consecutively. Therefore, they can both be removed from the circuit. Finally, the combination of an $X$ gate child of an input node followed by a controlled-not gate can, again, be optimized such that the $CX$ gate is replaced with a simple $X$ gate on the third qubit wire. The result is a circuit where the first qubit remains unchanged and only an $X$ gate is applied to the second and third qubit. This result is also depicted in Fig~\ref{fig:circuit_graph_optimized_complete}.   

\subsubsection{Graph Translation}
After all possible optimizations rules were applied and no others were enabled in turn, the only remaining step is to translate the circuit graph back to a programmatic description. The qubits for the circuit are easily declared by iterating over all input or output node. Additionally, the qubit count can be reduced by leaving out all qubits where the output node is the child of the input node after the optimization. In the case of the optimized circuit, depicted in Fig.~\ref{fig:circuit_graph_optimized_complete}, the first qubit $q_0$ can be skipped when adding the declaration to the translated program. 

For the gate applications, the only requirement is that, if a gate node is a descendent of another, its translated gate application statement must come after the statement of the ancestor node. Therefore, for most circuit graph there are multiple possible programs describing the circuit correctly. For example, when translating the completely optimized graph described above, the order of the $X$ gate applications to both the second and third qubit is irrelevant such that both possibilities, \ie either applying the gate to $q_1$ or $q_2$ first, are valid translations of the program. Furthermore, while iterating over all input or output nodes and adding the corresponding qubit and register declarations to the beginning of the program is the easiest approach, the order and placement of the declarations is also arbitrary as long as they are declared before their first use. 